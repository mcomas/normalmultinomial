---
title: "Likelihood estimation"
author: "Marc Comas-CufÃ­"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Likelihood estimation}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

The probability density function of a Normal-multinomial distribution is given by
\[
P(X = (x_1, \dots, x_D)) = \int_{p \in \mathcal{S}^D} \frac{(\sum x_i)!}{\prod x_i!} \prod x_i^{p_i} dN(p; \mu, \Sigma).
\]

Fitting the parameters $(\mu, \Sigma)$ using maximum likelihood it is not straightforward difficult because it is required to optimize $P(X = (x_1, \dots, x_D))$ with respect $\mu$ and $\Sigma$.


## Likelihood estimation 

The reduced likelihood function condition to unobserved $a = [a_1, ..., a_k] := alr([c_1, ..., c_K]) = [log(c_1/c_K), ..., log(c_k/c_K)]$ where $K = k +1$ is


\[
l(a) = -\frac{1}{2} (a-\mu)^{T} \Sigma^{-1} (a-\mu) + X_K log(\frac{1}{\kappa}) + \sum_{\ell = 1}^k X_\ell log(\frac{e^{a_\ell}}{\kappa}) 
\]

where $\kappa = 1 + e^{a_1} + \dots + e^{a_k}$.

#### First and second derivatives

\[
\frac{\partial l(a)}{\partial a_i} = - \sum_{\ell=1}^k (a_i-\mu_i) \Sigma^{-1}_{(i,\ell)} 
+ X_i \; \frac{\kappa-e^{a_i}}{\kappa} 
+ \sum_{\ell=1, \ell \neq i}^K X_{\ell}\; \frac{-e^{a_i}}{\kappa} 
\]

\[
\frac{\partial^2 l(a)}{\partial a_i^2} = -\Sigma^{-1}_{(i,i)} - \sum_{\ell=1}^K x_\ell \frac{e^{a_i} (\kappa - e^{a_i})}{\kappa^2}
\]

\[
\frac{\partial^2 l(a)}{\partial a_i \partial a_j} = -\Sigma^{-1}_{(i,j)} + \sum_{\ell=1}^K x_\ell \frac{e^{a_i+a_j}}{\kappa^2}
\]